---
title: "Reproducibility test"
author: "ross"
date: "8/25/2022"
output: html_document
---

```{r setup, include=FALSE}
options(rlib_downstream_check = FALSE)
knitr::opts_chunk$set(echo = TRUE)
```

```{r libs_fxns}
library(drc)
library(quantreg)
library(mcr)
library(broom)
library(lubridate)
library(tidyverse)

# Create custom ggplot theme
theme_custom <- function() {
  theme_bw(base_size = 10, base_family = "Arial") %+replace%
    theme(
      panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(), 
      panel.background = element_blank(),
      panel.border = element_rect(color = "black", fill = NA),
      legend.background = element_rect(fill = NA, colour = NA),
      axis.title = element_text(size = 7),
      axis.text = element_text(size = 5)
    )
}
```

# Compare ED50s measured in 2021 to ED50s measured in 2020
```{r}
# Import data from 2020

# Import June 2020 data
ed50_202006 <- read_csv("data/reproducibility/processed/ed50_202006.csv") %>%
  mutate(nursery = case_when(nursery == "RR" ~ "rrt", TRUE ~ tolower(nursery))) %>%
  select(nursery, geno = name, ed50 = estimate_ed50, std.error = std_error_ed50) %>%
  mutate(date = "202006")

### old data that was in repo but dont know how it was made
# ed50_2020 <- read_csv("~/Projects/CBASS_FL_Acer/data/processed/ed50_values.csv") %>%
#   mutate(nursery = case_when(nursery == "mote" ~ "mml", TRUE ~ tolower(nursery))) %>%
#   select(nursery, geno, ed50_2020 = ed50, std.error_2020 = std.error)

### new Oct 2020 data freshly exported from CBASS_FL_Acer repo
ed50_202010 <- read_csv("data/reproducibility/processed/ed50_2020.csv") %>%
  mutate(nursery = case_when(nursery == "RR" ~ "rrt", TRUE ~ tolower(nursery))) %>%
  select(nursery, geno = name, ed50 = ed50, std.error = std.error)

# In 2020, some genotypes were run multiple times from the same nursery, indicated by (A), (B), (C), etc.
# Group these, and get the average ED50 for 2020 for each genotype from each nursery
ed50_202010 <- ed50_202010 %>%
  separate(geno, into = c("geno", "replicate"), sep = "\\(") %>%
  group_by(geno, nursery) %>%
  summarise(ed50 = weighted.mean(ed50, 1/std.error^2), 
            std.error = mean(std.error)) %>%
  ungroup() %>%
  select(nursery, geno, ed50, std.error) %>%
  mutate(date = "202010")

# Tidy 2021 data and join with 2020
### Choose filtered or unfiltered 2021 data
ed50_202109 <- read_csv("data/reproducibility/processed/ed50_202109.csv")
ed50_202109 <- ed50_202109 %>%
  mutate(ed50 = ed50.f,
         std.error = std.error.f,
         nursery = tolower(nursery)) %>%
  select(nursery, geno, ed50, std.error) %>%
  mutate(date = "202109")

# Combine all data and get only genos tested more than once
longdf <- bind_rows(ed50_202006, ed50_202010, ed50_202109) %>%
  group_by(nursery, geno) %>%
  filter(n() > 1) %>%
  ungroup()
```

# New analysis 2023

## Prefilter data based on ED50 std.error
```{r}
# Identify lower quality data as highest 10% standard error of ED50 parameter estimates
outliers <- longdf %>%
  group_by(nursery, geno) %>%
  summarize(meanse = mean(std.error)) %>%
  ungroup() %>%
  filter(meanse > quantile(meanse, 0.9))

# Remove genotypes with highest 10% standard error of ED50 parameter estimates
toplongdf <- longdf #%>% filter(!geno %in% outliers$geno)
```

# Plot and analyze unadjusted data
```{r}
# Analyze sources of variance
mod <- lm(ed50 ~ geno + nursery:date, data = toplongdf)
anova(mod)
ress <- augment(mod, toplongdf) %>% arrange(-.cooksd)
hist(ress$.cooksd, breaks = 50)
highcooks <- ress %>% filter(.cooksd > 0.05)

# Remove genotypes with highest cooksD
toplongdf <- toplongdf %>% filter(!geno %in% highcooks$geno)

topwidedf <- toplongdf %>%
  pivot_wider(names_from = date, values_from = c(ed50, std.error))



mod2 <- lm(ed50_202109 ~ ed50_202010 + nursery, data = topwidedf)
anova(mod2)

unadj.corr <- ggplot(topwidedf, aes(x = ed50_202010)) +
  facet_wrap(~ nursery) +
  #geom_point(data = means, aes(y = ed50_202109), pch = 1, size = 3, color = "red", alpha = 0.5) + 
  geom_point(aes(y = ed50_202109), pch = 1) +
  geom_point(aes(y = ed50_202006), pch = 2) +
  geom_abline(slope = 1, intercept = 0, lty = 2) +
  #geom_label(aes(y = ed50_202109, label = geno)) +
  #stat_cor() +
  coord_fixed(xlim = range(toplongdf$ed50), ylim = range(toplongdf$ed50)) +
  theme_custom(); unadj.corr




# Get all pairwise differences between measurements of the same geno at the same nursery
res.unadj <- toplongdf %>% 
  group_by(nursery, geno) %>% 
  summarise(diff = combn(ed50,2,diff),
            test = combn(date,2,paste, simplify = FALSE)) %>%  
  mutate(pair = unlist(lapply(test, function(x)paste(x,collapse="-")))) %>%  
  select(-test) %>%
  ungroup()


# Get ECDF for plotting
dens <- density(abs(res.unadj$diff), adjust = 0.01)
dens <- tibble(x = dens$x, y = dens$y) %>%
  mutate(cd = cumsum(y)/sum(y))
# Get degree diffs for x% of cases from cumulative density
conf0.5 <- dens$x[which.min(abs(0.5 - dens$cd))]
conf0.9 <- dens$x[which.min(abs(0.9 - dens$cd))]

myecdf <- ggplot(res.unadj, aes(x = abs(diff))) +
  geom_segment(aes(y = 0.5, yend = 0.5, x = 0, xend = conf0.5), lty = 2, alpha = 0.4, lwd = 0.25) +
  geom_segment(aes(x = conf0.5, xend = conf0.5, y = 0, yend = 0.5), lty= 2, alpha = 0.4, lwd = 0.25) +
  geom_segment(aes(y = 0.9, yend = 0.9, x = 0, xend = conf0.9), lty = 2, alpha = 0.4, lwd = 0.25) +
  geom_segment(aes(x = conf0.9, xend = conf0.9, y = 0, yend = 0.9), lty= 2, alpha = 0.4, lwd = 0.25) +
  #geom_rect(data = myvals, aes(xmin = 0, xmax = diff, ymin = 0, ymax = perc), alpha = 0.2) +
  stat_ecdf(color = "red", alpha = 0.5) +
  scale_x_continuous(expand = c(0, 0), breaks = seq(0, 2, 0.25)) +
  coord_cartesian(xlim = c(0, 1.2)) +
  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.9, 1), labels = scales::percent, expand = c(0, 0)) +
  labs(x = "|Test 1 - Test 2| ΔED50 (°C)", y = "Percent of cases") +
  theme_custom(); myecdf
```


# Remove nursery / year effects
```{r}
# Model nursery and year effects to remove from data
indf <- toplongdf
mod <- lm(ed50 ~ nursery:date, data = indf)
# Add residuals from nursery*year fitted values to the grand mean ED50
out <- augment(mod, indf) %>%
  mutate(ed50_adj = mean(indf$ed50) + .resid) %>%
  select(geno, nursery, date, ed50, ed50_adj)
res.adj <- out %>% 
  group_by(nursery, geno) %>% 
  summarise(diff = combn(ed50_adj,2,diff),
            test = combn(date,2,paste, simplify = FALSE)) %>%  
  mutate(pair = unlist(lapply(test, function(x)paste(x,collapse="-")))) %>%  
  select(-test) %>%
  ungroup()

# Get ECDF for plotting
adjdens <- density(abs(res.adj$diff), adjust = 0.1)
adjdens <- tibble(x = adjdens$x, y = adjdens$y) %>%
  mutate(cd = cumsum(y)/sum(y))
# Get degree diffs for x% of cases from cumulative density
adjconf0.5 <- adjdens$x[which.min(abs(0.5 - adjdens$cd))]
adjconf0.9 <- adjdens$x[which.min(abs(0.9 - adjdens$cd))]


# Plot adjusted ED50s 2021 vs. 2020
adj.corr <- out %>% pivot_wider(names_from = date, values_from = c(ed50, ed50_adj)) %>%
  ggplot(aes(x = ed50_adj_202010)) +
  geom_point(aes(y = ed50_adj_202109), pch = 1) + #aes(color = sum.std.error)) +
  geom_point(aes(y = ed50_adj_202006), pch = 2) +
  #geom_smooth(method = "lm") +
  #geom_label(aes(label = geno, y = ed50_adj_202109), size = 2) +
  geom_ribbon(aes(ymin = ..x.. - adjconf0.5, ymax = ..x.. + adjconf0.5), alpha = 0.25) +
  geom_ribbon(aes(ymin = ..x.. - adjconf0.9, ymax = ..x.. + adjconf0.9), alpha = 0.25) +
  #annotate("text", x = 35, y = 37, label = round(adjconf0.9, 3)) +
  #annotate("text", x = 35, y = 36.8, label = round(adjconf0.5, 3)) +
  labs(x = "ED50 (°C) in Test 1", y = "ED50 (°C) in Test 2") +
  geom_abline(aes(slope = 1, intercept = 0), lty = 2, lwd = 0.25) +
  theme_custom() +
  #theme(legend.position = "none") +
  coord_fixed()


ecdf2 <- myecdf +
  #geom_segment(aes(y = 0.5, yend = 0.5, x = 0, xend = adjconf0.5), lty = 2) +
  geom_segment(aes(x = adjconf0.5, xend = adjconf0.5, y = 0, yend = 0.5), lty= 2, lwd = 0.25) +
  geom_text(x = adjconf0.5, y = 0.02, label = round(adjconf0.5, 2), adj = 1) +
  #geom_segment(aes(y = 0.9, yend = 0.9, x = 0, xend = adjconf0.9), lty = 2) +
  geom_segment(aes(x = adjconf0.9, xend = adjconf0.9, y = 0, yend = 0.9), lty= 2, lwd = 0.25) +
  geom_text(x = adjconf0.9, y = 0.02, label = round(adjconf0.9, 2), adj = 1) +
  #geom_rect(data = myvals, aes(xmin = 0, xmax = diff, ymin = 0, ymax = perc), alpha = 0.2) +
  stat_ecdf(data = res.adj, color = "red"); ecdf2
```

```{r}
# Plot combined figure
repro.fig <- plot_grid(unadj.corr, adj.corr, ecdf2, nrow = 1, 
                       labels = "auto", rel_widths = c(0.42, 0.29, 0.29))
ggsave(repro.fig, filename = "output/reprofig.png", width = 183, height = 80, units = "mm")
```





####------
# everything below is older code from arond reef futures conference...
# Filter out ED50 measurements with high error (lower confidence in value)


# Estimate repeatability of ED50 for same genotype
```{r}
# Repeatability
library(rptR)
Rout <- rpt(ed50 ~ nursery * date  + (1|geno), data = toplongdf, 
           grname = c("geno", "Overdispersion", "Fixed", "Residual"), 
           nboot = 1000, parallel = TRUE, adjusted = TRUE)
Rout
plot(Rout)
summary(Rout)
```


# Repeatability of pairwise ranks
```{r}
# Get all pairwise differences in adjusted ED50 between high confidence genos in 2020 and 2021
test <- out %>%
  group_by(date) %>%
  summarise(diff = combn(ed50_adj, 2, diff),
            test = combn(geno, 2, paste, simplify = FALSE)) %>%  
  mutate(pair = unlist(lapply(test, function(x) paste(x, collapse="-")))) %>%  
  select(-test) %>%
  ungroup()

test2 <- test %>%
  pivot_wider(names_from = date, values_from = diff) %>%
  # mutate(`202006rank` = sign(`202006`) == sign(`202010`),
  #        `202109rank` = sign(`202109`) == sign(`202010`)) %>%
  #select(pair, diff202010 = `202010`, `202006rank`, `202109rank`) %>%
  #pivot_longer(c(`202006rank`, `202109rank`), values_to = "samerank") %>%
  pivot_longer(c(`202006`, `202109`)) %>%
  drop_na()

ggplot(test2, aes(x = `202010`, y = value)) + geom_point() +
  geom_smooth()

test3 <- test2 %>%
  mutate(abs202010 = abs(`202010`),
         tval = case_when(`202010` < 0 ~ value * -1, TRUE ~ value)) %>%
  separate(pair, into = c("geno1", "geno2"), sep = "-")
mod <- lm(tval ~ abs202010, data = test3)

newdat <- data.frame(abs202010 = seq(0,1.55,0.01))
pred0.5 <- data.frame(predict(mod, newdata = newdat, interval = "predict", level = 0.5, re.form = NA))
pred0.9 <- data.frame(predict(mod, newdata = newdat, interval = "predict", level = 0.95))
preds <- bind_cols(newdat, p0.5 = pred0.5, p0.9 = pred0.9) %>%
  as_tibble()

ggplot(test3, aes(x = abs202010)) + 
  geom_point(aes(y = tval), alpha = 0.3, pch = 16) +
  geom_smooth(aes(y = tval), method = "lm", se = FALSE) +
  geom_ribbon(data = preds, aes(ymin = lwr...3, ymax = upr...4), alpha = 0.2) +
  geom_ribbon(data = preds, aes(ymin = lwr...6, ymax = upr...7), alpha = 0.2) +
  geom_hline(aes(yintercept = 0), lty = 1, lwd = 0.25) +
  #scale_x_continuous(expand = c(0, 0)) +
  theme_custom()

### what about genos as random?
# fit mixed model
library(merTools)
mod <- lmer(tval ~ abs202010 + (1|geno1) + (1|geno2) + (1|name), data = test3)
fit <- data.frame(fit = predict(mod, newdata = newdat, re.form = NA)) %>% bind_cols(newdat)
anova(mod)
newdata <- tibble(newdat, geno1 = "ML6555", geno2 = "ML1fsdf0", name = "20200fd6")
# use "predictInterval" -- but this makes you specify random factors? how to do across all?
PI <- predictInterval(merMod = mod, newdata = newdata,
                      level = 0.95, n.sims = 1000,
                      stat = "median", type = "linear.prediction",
                      include.resid.var = TRUE) %>%
  as_tibble() %>% bind_cols(newdata)

# use arm::sim
PI.arm <- data.frame(
  fit=apply(fitted(PI.arm.sims, fm1), 1, function(x) quantile(x, 0.500)),
  upr=apply(fitted(PI.arm.sims, fm1), 1, function(x) quantile(x, 0.975)),
  lwr=apply(fitted(PI.arm.sims, fm1), 1, function(x) quantile(x, 0.025))
)


ggplot(test3, aes(x = abs202010)) + 
  geom_point(aes(y = tval), alpha = 0.3, pch = 16) +
  geom_line(data = fit, aes(y = fit)) +
  #geom_smooth(aes(y = tval), method = "lm", se = FALSE) +
  geom_ribbon(data = PI, aes(ymin = lwr, ymax = upr), alpha = 0.2) +
  geom_hline(aes(yintercept = 0), lty = 1, lwd = 0.25) +
  #scale_x_continuous(expand = c(0, 0)) +
  theme_custom()








####

mod <- glm(samerank ~ abs(diff202010), data = test2, family = "binomial")
anova(mod)

# Get probability that rank order is same given difference in 2020 ED50s
emm <- emmeans::emmeans(mod, specs = "diff202010", 
                        at = list(diff202010 = seq(0,2.0,0.01)),
                        type = "response")
ggplot(data.frame(emm), aes(x = diff202010, y = prob)) +
  geom_line() +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL), alpha = 0.2) +
  labs(x = "Pairwise difference in ED50 (°C)\nin Test 1 (2020)",
       y = "Probability of same rank order\nin Test 2 (2021)") +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 2)) +
  theme_custom() +
  theme(text = element_text(size = 14)) +
  coord_cartesian(ylim = c(0.5, 1), expand = c(0, 0))


```

# How confident can we be in identifying GROUPS of more/less tolerant corals?
```{r}
top <- filter(out, date == "202010") %>%
  filter(ed50_adj > quantile(ed50_adj, 0.5))
bottom <- filter(out, date == "202010") %>%
  filter(ed50_adj < quantile(ed50_adj, 0.5))

top2 <- filter(out, date == "202109", geno %in% top$geno)
bottom2 <- filter(out, date == "202109", geno %in% bottom$geno)

test <- bind_rows(top = top2, bottom = bottom2, .id = "cat")
test
mod <- lm(ed50_adj ~ cat, data = test)
anova(mod)

g1 <- out %>% filter(date == "202010") %>% sample_n(10)
g2 <- out %>% filter(date == "202010") %>% sample_n(10)
diff <- mean(g1$ed50_adj) - mean(g2$ed50_adj)

####
# GET 2 RANDOM GROUPS OF N CORALS. calc mean diff btw groups in 202010, 202109 (and 202006).
# Look at value of mean difference in 202109 (and 202006) vs. 202010, and get pred. interval.
### toooo many groups! need to get a subset upfront....
set.seed(4)
# Pick subset of genos from equal bins across range of ed50_adj distribution from oct2020
oct2010 <- out %>% 
  filter(date == "202010") 
bins <- oct2010 %>%
  mutate(bin = cut(ed50_adj, breaks = seq(min(ed50_adj), max(ed50_adj), length.out = 10),
         include.lowest = TRUE))
bins %>% count(bin)
subset <- bins %>% 
  group_by(bin) %>%
  slice_sample(n = 3)
indf <- out %>%
  filter(geno %in% subset$geno) %>%
  pivot_wider(names_from = "date", values_from = c(ed50, ed50_adj)) %>%
  select(geno, `202010` = ed50_adj_202010, `202006` = ed50_adj_202006, `202109` = ed50_adj_202109) %>%
  pivot_longer(c(`202006`, `202109`)) %>% drop_na()
ran <- function(df, groupsize) {
  g <- indf %>% group_by(geno) %>% slice_sample(n=1) %>% ungroup() %>%
    slice_sample(n = 2 * groupsize)
  g <- g %>% mutate(group = c(rep(1, groupsize), rep(2, groupsize)))
  r <- g %>% group_by(group) %>% 
    summarize(mean.1 = mean(`202010`), mean.2 = mean(value)) %>%
    summarize_all(diff)
  return(r)
}

ran(indf, 3)

res <- replicate(1000, ran(indf, 6), simplify = FALSE)
res2 <- map_dfr(res, bind_rows)
res2 <- res2 %>% 
  mutate(absdiff1 = abs(mean.1), diff2 = mean.2 * sign(mean.1))
mod <- lm(diff2 ~ absdiff1, data = res2)
newdat <- data.frame(absdiff1 = seq(0, 1.5, 0.1))
pred <- data.frame(predict(mod, newdata = newdat, interval = "predict", level = 0.9)) %>% bind_cols(newdat)
ggplot(res2, aes(x = absdiff1, y = diff2)) + 
  geom_point(alpha = 0.2) +  
  geom_ribbon(aes(y = fit, ymin = lwr, ymax = upr), data = pred, alpha = 0.2) +
  coord_cartesian(ylim = c(-1.5, 1.5), xlim = c(0, 1.5))
  

n <- 3
df <- out %>% 
  pivot_wider(names_from = "date", values_from = c(ed50, ed50_adj)) %>%
  summarize(group = combn(geno, n, paste, simplify = FALSE),
            mean_202006 = combn(ed50_adj_202006, n, mean),
            mean_202010 = combn(ed50_adj_202010, n, mean),
            mean_202109 = combn(ed50_adj_202109, n, mean))
df <- df %>% filter(!(is.na(mean_202006) & is.na(mean_202109)))
dff <- df %>% sample_n(1000)
dff1 <- rename_with(dff, ~ paste0(.x, ".1"))
dff2 <- rename_with(dff, ~ paste0(.x, ".2"))
comp2 <- crossing(dff1, dff2) %>%    # this has a - b and b - a, so filtering > 0.5 (instead of abs) still has all comparisons
  dplyr::filter(mean_202010.1 > mean_202010.2) %>%
  summarize(diff202010 = mean_202010.1 - mean_202010.2,
            diff202006 = mean_202006.1 - mean_202006.2,
            diff202109 = mean_202109.1 - mean_202109.2) %>%
  pivot_longer(c(diff202006, diff202109)) %>%
  drop_na()

mod <- lm(value ~ diff202010, data = comp2)
newdat <- data.frame(diff202010 = seq(0, 1.5, 0.1))
pred <- data.frame(predict(mod, newdata = newdat, interval = "predict", level = 0.9)) %>% bind_cols(newdat)
ggplot(comp2, aes(x = diff202010, y = value)) + 
  #geom_point(alpha = 0.2) +
  geom_ribbon(aes(y = fit, ymin = lwr, ymax = upr), data = pred, alpha = 0.2) +
  coord_cartesian(ylim = c(-1.5, 1.5), xlim = c(0, 1.5))


```




```{r old_code, include = F, eval = F, echo = F}

#Repeatability coefficient
# Mean within-subject sample variance
res3 <- res2 %>% rowwise() %>% mutate(var = var(c(ed50_2021, ed50_2020)))
var_w <- mean(res3$var, na.rm = TRUE)
# Within-subject sample standard deviation
s_w <- sqrt(var_w)
# Coefficient of repeatability
rc95 <- 1.96 * sqrt(2) * s_w
rc95   # 95% of the time, repeat measurements will differ by less than rc     0.84
rc90 <- 1.645 * sqrt(2) * s_w
rc90

# statistical repeatability
probs <- tibble(
  p = seq(0.01, 0.99, 0.01),
  t = qt((1-seq(0.01,0.99,0.01))/2, lower.tail = F, df = Inf),
  y = t * sqrt(2) * s_w
)

ggplot(probs, aes(y = p, x = y)) +
  geom_line() +
  labs(y = "Percent of cases (genets)", x = "Test - retest difference in ED50 (°C)") +
  geom_vline(aes(xintercept = 0.95), lty = 2) +
  annotate("text", x = 0.8, y = 0.7, label = "Repeatability coefficient")

val <- qt((1-seq(0.01,0.99,0.01))/2, lower.tail = F, df = Inf) * sqrt(2) * s_w
plot(seq(0.01,0.99,0.01), val)
pt(seq(0.01,0.99,0.01), df = Inf) * sqrt(2) * s_w
plot(seq(0.01,0.99,0.01), tt)



```

